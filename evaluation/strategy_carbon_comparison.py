"""
ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒ
ç›®æ ‡ï¼šå¯¹æ¯”ä¸åŒç­–ç•¥ï¼ˆéšæœºç­–ç•¥ã€å„ç§è®­ç»ƒæ¨¡å‹ï¼‰åœ¨ä¸åŒé…ç½®ä¸‹çš„ç¢³æ’æ”¾æ•ˆæœ
æ”¯æŒæ‰©å±•ï¼šå¯ä»¥è½»æ¾æ·»åŠ æ›´å¤šç®—æ³•æ¨¡å‹è¿›è¡Œå¯¹æ¯”
"""
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os
import importlib
import types

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)
# æ·»åŠ modelç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(project_root, 'model'))

from environment import HomeEnergyManagementEnv
import random
from datetime import datetime
import warnings
import multiprocessing as mp

# è®¾ç½®matplotlibåç«¯å’Œè­¦å‘Š
warnings.filterwarnings('ignore')  # å¿½ç•¥è­¦å‘Š
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt

# è®¾ç½®å­—ä½“ä¸ºæ”¯æŒè‹±æ–‡çš„å­—ä½“
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# å…¼å®¹æ€§å«ç‰‡ï¼šéƒ¨åˆ†åºåˆ—åŒ–æ–‡ä»¶åœ¨ä¿å­˜æ—¶ä¾èµ– numpy._coreï¼ˆNumPy 2.x å‘½åï¼‰ï¼Œ
# åœ¨å½“å‰ç¯å¢ƒï¼ˆNumPy 1.21.xï¼‰ä¸­ä¸å­˜åœ¨è¯¥æ¨¡å—ï¼Œå¯¼è‡´ torch.load ååºåˆ—åŒ–å¤±è´¥ã€‚
# å¦‚æœæ£€æµ‹ä¸åˆ° numpy._coreï¼Œåˆ™å°† numpy.core ä»£ç†ä¸º numpy._coreã€‚
try:
    if importlib.util.find_spec('numpy._core') is None:
        import numpy.core as _np_core
        _proxy = types.ModuleType('numpy._core')
        _proxy.__dict__.update(_np_core.__dict__)
        sys.modules['numpy._core'] = _proxy
except Exception:
    pass

class StrategyCarbonComparison:
    def __init__(self):
        # ç¢³å¼ºåº¦å› å­è®¾ç½®
        self.carbon_intensity_mapping = {
            'low_valley': 0.3,    # ä½è°·æœŸï¼šæ¸…æ´èƒ½æºä¸»å¯¼  
            'flat': 0.6,          # å¹³æ®µæœŸï¼šæ¸…æ´èƒ½æºä¸ç«ç”µæ··åˆ  kgCO2/kWh
            'peak': 0.9           # é«˜å³°æœŸï¼šç«ç”µä¸»å¯¼  kgCO2/kWh
        }
        
        # å®éªŒå‚æ•°
        self.num_episodes = 10
        self.episode_length = 336  # 7å¤©
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        self.project_root = os.path.dirname(self.current_dir)
        model_dir = os.path.join(self.project_root, 'model', 'saved_models')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(model_dir, exist_ok=True)
        
        # ç­–ç•¥é…ç½®ï¼šæ”¯æŒæ‰©å±•å¤šç§ç­–ç•¥
        self.strategies = {
            'random': {
                'name': 'éšæœºç­–ç•¥',
                'model_path': None,
                'strategy_func': self.get_random_action
            },
            'proposed_rl': {
                'name': 'PPOç®—æ³•',
                'model_path': os.path.join(model_dir, 'proposed_rl.pth'),
                'strategy_func': self.get_model_action
            },
            'rainbow_dqn': {
                'name': 'Rainbow DQN',
                'model_path': os.path.join(model_dir, 'rainbow_dqn_model_20250805_022938_norm.pth'),
                'strategy_func': self.get_model_action
            },
            'ddpg': {
                'name': 'DDPGç®—æ³•',
                'model_path': os.path.join(model_dir, 'ddpg.pth'),
                'strategy_func': self.get_model_action
            },
            'td3': {
                'name': 'TD3ç®—æ³•',
                'model_path': os.path.join(model_dir, 'td3_model_min.pth'),
                'strategy_func': self.get_model_action
            },
            'sac': {
                'name': 'SACç®—æ³•',
                'model_path': os.path.join(model_dir, 'sac2_model_min.pth'),
                'strategy_func': self.get_model_action
            }
        }
        
        # å®éªŒé…ç½®ï¼šç»Ÿä¸€ä½¿ç”¨å®Œæ•´é…ç½®
        self.configurations = {
            'full_optimization': {
                'name': 'å®Œæ•´ä¼˜åŒ–é…ç½®',
                'mask_type': 'full'
            }
        }
        
        # ç»“æœå­˜å‚¨ï¼š{strategy}_{config} æ ¼å¼
        self.results = {}
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        self.loaded_models = {}
        self.load_all_models()
    
    def _safe_torch_load(self, model_path):
        """å…¼å®¹æ€§å¢å¼ºçš„torch.loadï¼Œå°½é‡é¿å…ç¯å¢ƒå·®å¼‚å¯¼è‡´çš„ååºåˆ—åŒ–å¤±è´¥"""
        # ä¼˜å…ˆå°è¯•weights_onlyï¼ˆè‹¥PyTorchç‰ˆæœ¬æ”¯æŒï¼‰
        try:
            return torch.load(model_path, map_location='cpu', weights_only=True)
        except TypeError:
            pass
        except Exception:
            pass
        # å¸¸è§„åŠ è½½
        try:
            return torch.load(model_path, map_location='cpu')
        except Exception:
            pass
        # å°è¯•ä½¿ç”¨pickleä»¥latin1ç¼–ç å›é€€
        try:
            import pickle
            with open(model_path, 'rb') as f:
                return pickle.load(f, encoding='latin1')
        except Exception as e:
            raise e

    def _extract_checkpoint_keys_worker(self, model_path, required_keys, conn):
        """å­è¿›ç¨‹å·¥ä½œå‡½æ•°ï¼šä»…æå–æ‰€éœ€é”®ï¼Œé¿å…ä¸»è¿›ç¨‹å¡æ­»"""
        try:
            import sys as _sys
            import importlib as _importlib
            import types as _types
            import os as _os
            # é™åˆ¶å­è¿›ç¨‹çš„çº¿ç¨‹æ•°ï¼Œé¿å…BLAS/OMPå¡æ­»
            try:
                _os.environ.setdefault('OMP_NUM_THREADS', '1')
                _os.environ.setdefault('MKL_NUM_THREADS', '1')
            except Exception:
                pass
            # å­è¿›ç¨‹å†…æ³¨å…¥ numpy._core å…¼å®¹å«ç‰‡ï¼Œé¿å… structseq ç›¸å…³ååºåˆ—åŒ–å´©æºƒ
            try:
                if _importlib.util.find_spec('numpy._core') is None:
                    import numpy.core as _np_core
                    _proxy = _types.ModuleType('numpy._core')
                    _proxy.__dict__.update(_np_core.__dict__)
                    _sys.modules['numpy._core'] = _proxy
            except Exception:
                pass

            import torch
            try:
                torch.set_num_threads(1)
            except Exception:
                pass
            ckpt = None
            # 1) ä¼˜å…ˆ weights_onlyï¼ˆè‹¥å¯ç”¨ï¼‰
            try:
                ckpt = torch.load(model_path, map_location='cpu', weights_only=True)
            except TypeError:
                pass
            except Exception:
                pass
            # 2) å¸¸è§„åŠ è½½
            if ckpt is None:
                try:
                    ckpt = torch.load(model_path, map_location='cpu')
                except Exception:
                    ckpt = None
            # 3) pickle latin1 å›é€€
            if ckpt is None:
                try:
                    import pickle as _pickle
                    with open(model_path, 'rb') as f:
                        ckpt = _pickle.load(f, encoding='latin1')
                except Exception as e:
                    conn.send((False, str(e)))
                    return
            slim = {}
            if isinstance(required_keys, dict):
                # å…è®¸(key -> default)å½¢å¼
                for k, default in required_keys.items():
                    slim[k] = ckpt.get(k, default)
            else:
                for k in required_keys:
                    if k in ckpt:
                        slim[k] = ckpt[k]
            conn.send((True, slim))
        except Exception as e:
            conn.send((False, str(e)))
        finally:
            conn.close()

    def _load_checkpoint_minimal(self, model_path, required_keys, timeout_sec=180):
        """åœ¨å­è¿›ç¨‹ä¸­æœ€å°åŒ–åŠ è½½checkpointï¼Œä»…è¿”å›æŒ‡å®šé”®ï¼Œè¶…æ—¶åˆ™æ”¾å¼ƒ"""
        parent_conn, child_conn = mp.Pipe(duplex=False)
        proc = mp.Process(target=self._extract_checkpoint_keys_worker, args=(model_path, required_keys, child_conn))
        proc.start()
        proc.join(timeout=timeout_sec)
        if proc.is_alive():
            try:
                proc.terminate()
            except Exception:
                pass
            return None, f"load timeout (> {timeout_sec}s)"
        if parent_conn.poll():
            ok, payload = parent_conn.recv()
            if ok:
                return payload, None
            return None, payload
        return None, "unknown load failure"
        
    def load_all_models(self):
        """åŠ è½½æ‰€æœ‰é…ç½®çš„æ¨¡å‹"""
        print("ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹...")
        for strategy_key, strategy_config in self.strategies.items():
            model_path = strategy_config['model_path']
            print(f"ğŸ“ æ£€æŸ¥ç­–ç•¥ {strategy_key}: è·¯å¾„ = {model_path}")
            
            if model_path and os.path.exists(model_path):
                print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹åŠ è½½ {strategy_config['name']} æ¨¡å‹...")
                model = self.load_model(model_path, strategy_key)
                self.loaded_models[strategy_key] = model
                if model:
                    print(f"âœ… {strategy_config['name']} æ¨¡å‹åŠ è½½æˆåŠŸ")
                else:
                    print(f"âŒ {strategy_config['name']} æ¨¡å‹åŠ è½½å¤±è´¥")
            else:
                self.loaded_models[strategy_key] = None
                if model_path:
                    print(f"âŒ {strategy_config['name']} æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºç›®å½•å†…å®¹
                    model_dir = os.path.dirname(model_path)
                    if os.path.exists(model_dir):
                        print(f"   ğŸ“‚ ç›®å½•å†…å®¹: {os.listdir(model_dir)}")
                    else:
                        print(f"   ğŸ“‚ ç›®å½•ä¸å­˜åœ¨: {model_dir}")
                else:
                    print(f"â„¹ï¸ {strategy_config['name']} æ— éœ€åŠ è½½æ¨¡å‹")
    
    def load_model(self, model_path, strategy_key):
        """åŠ è½½å•ä¸ªæ¨¡å‹ï¼ˆæ ¹æ®ç­–ç•¥ç±»å‹ï¼‰"""
        try:
            print(f"   â³ æ­£åœ¨è¯»å–checkpoint({strategy_key}) -> {model_path}")
            # SAC/TD3 ä½¿ç”¨å­è¿›ç¨‹æœ€å°åŒ–åŠ è½½ï¼Œé¿å…ä¸»è¿›ç¨‹å¡æ­»
            if strategy_key in ('sac', 'td3'):
                # å¯¹äºå·²ç²¾ç®€çš„æœ€å°æ–‡ä»¶ï¼Œç›´æ¥åœ¨ä¸»è¿›ç¨‹å®‰å…¨åŠ è½½ï¼Œé¿å…Windowsä¸‹å­è¿›ç¨‹å¥æŸ„é—®é¢˜
                if os.path.basename(model_path).endswith('_min.pth'):
                    checkpoint = self._safe_torch_load(model_path)
                    print(f"   âœ… checkpointå·²è¯»å–({strategy_key})ï¼ŒåŒ…å«é”®: {list(checkpoint.keys())}")
                else:
                    required = ['training_config', 'state_keys', 'actor_state_dict']
                    checkpoint, err = self._load_checkpoint_minimal(model_path, required, timeout_sec=180)
                    if checkpoint is None:
                        print(f"   âŒ {strategy_key} å­è¿›ç¨‹æœ€å°åŒ–åŠ è½½å¤±è´¥: {err}")
                        return None
                    print(f"   âœ… checkpointå·²è¯»å–({strategy_key})ï¼ŒåŒ…å«é”®: {list(checkpoint.keys())}")
            else:
                # ä½¿ç”¨å…¼å®¹æ€§å¢å¼ºçš„å®‰å…¨åŠ è½½ï¼Œé¿å…ä¸åŒç¯å¢ƒä¸‹çš„ååºåˆ—åŒ–é—®é¢˜
                checkpoint = self._safe_torch_load(model_path)
                print(f"   âœ… checkpointå·²è¯»å–({strategy_key})ï¼ŒåŒ…å«é”®: {list(checkpoint.keys())[:6]} ...")
            
            if strategy_key == 'proposed_rl':
                return self.load_ppo_model(checkpoint)
            elif strategy_key == 'rainbow_dqn':
                return self.load_rainbow_dqn_model(checkpoint)
            elif strategy_key == 'ddpg':
                return self.load_ddpg_model(checkpoint)
            elif strategy_key == 'td3':
                return self.load_td3_model(checkpoint)
            elif strategy_key == 'sac':
                return self.load_sac_model(checkpoint)
            else:
                print(f"âš ï¸ æœªçŸ¥çš„ç­–ç•¥ç±»å‹: {strategy_key}")
                return None
                
        except Exception as e:
            print(f"âŒ {strategy_key} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_ppo_model(self, checkpoint):
        """åŠ è½½PPOæ¨¡å‹"""
        try:
            if isinstance(checkpoint, dict) and 'shared_backbone_state_dict' in checkpoint:
                # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
                model_path = os.path.join(self.project_root, 'model')
                if model_path not in sys.path:
                    sys.path.append(model_path)
                from PPO_3rd import HomeEnergyPPO
                
                # åˆ›å»ºç¯å¢ƒå®ä¾‹
                env = HomeEnergyManagementEnv()
                
                # ä»checkpointè·å–è®­ç»ƒé…ç½®
                training_config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºå®Œæ•´çš„æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨PPO_3rdçš„å‚æ•°ï¼‰
                agent = HomeEnergyPPO(
                    env=env,
                    state_dim=training_config['state_dim'],
                    hidden_dim=training_config['hidden_dim'],
                    action_space_config=training_config['action_space_config'],
                    gamma=training_config['gamma'],
                    lmbda=training_config['lmbda'],
                    eps=training_config['eps'],
                    epochs=training_config['epochs'],
                    ent_coef=training_config['ent_coef'],
                    max_grad_norm=training_config['max_grad_norm'],
                    device='cpu',
                    constraint_mode=training_config.get('constraint_mode', 'none'),
                    use_state_normalization=training_config.get('use_state_normalization', True),
                    use_advantage_normalization=True,
                    use_dynamic_mask=training_config.get('use_dynamic_mask', True),
                    constraint_config=training_config.get('constraint_config', None)
                )
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.shared_backbone.load_state_dict(checkpoint['shared_backbone_state_dict'])
                agent.actor_branches.load_state_dict(checkpoint['actor_branches_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.shared_backbone.eval()
                for branch in agent.actor_branches.values():
                    branch.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºçŠ¶æ€æ ‡å‡†åŒ–ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from PPO_3rd import RunningStats
                    running_stats = RunningStats(shape=training_config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint['running_stats_std']
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint['state_keys']
                }
            else:
                print("âŒ PPOæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                print(f"   æœŸæœ›çš„é”®: shared_backbone_state_dict")
                print(f"   å®é™…çš„é”®: {list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'éå­—å…¸ç±»å‹'}")
                return None
        except Exception as e:
            print(f"âŒ PPOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_rainbow_dqn_model(self, checkpoint):
        """åŠ è½½Rainbow DQNæ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from dqn import RainbowDQN
            
            # åˆ›å»ºç¯å¢ƒå®ä¾‹
            env = HomeEnergyManagementEnv()
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“ï¼ˆå¼ºåˆ¶ä½¿ç”¨CPUï¼‰
                import torch
                original_device = torch.cuda.current_device() if torch.cuda.is_available() else None
                
                agent = RainbowDQN(
                    state_dim=config['state_dim'],
                    hidden_dim=config['hidden_dim'],
                    action_space_config=config['action_space_config'],
                    lr=1e-4,  # ä½¿ç”¨é»˜è®¤å€¼ï¼Œå› ä¸ºæ¨¡å‹æ–‡ä»¶ä¸­æ²¡æœ‰ä¿å­˜è¿™äº›è®­ç»ƒå‚æ•°
                    gamma=config.get('gamma', 0.96),
                    tau=config.get('tau', 0.01),
                    buffer_size=100000,  # ä½¿ç”¨é»˜è®¤å€¼
                    batch_size=config.get('batch_size', 512),
                    epsilon_start=1.0,  # ä½¿ç”¨é»˜è®¤å€¼
                    epsilon_end=0.05,   # ä½¿ç”¨é»˜è®¤å€¼
                    epsilon_decay=0.995,  # ä½¿ç”¨é»˜è®¤å€¼
                    n_step=config.get('n_step', 3),
                    alpha=config.get('alpha', 0.6),
                    beta=config.get('beta', 0.4)
                )
                
                # ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½åœ¨CPUä¸Š
                agent.device = torch.device('cpu')
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.shared_backbone.load_state_dict(checkpoint['shared_backbone_state_dict'])
                agent.q_branches.load_state_dict(checkpoint['q_branches_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç¡®ä¿åœ¨CPUä¸Š
                agent.shared_backbone.eval()
                agent.shared_backbone.to('cpu')
                for branch in agent.q_branches.values():
                    branch.eval()
                    branch.to('cpu')
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from PPO_3rd import RunningStats
                    running_stats = RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint['running_stats_std']
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ Rainbow DQNæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ Rainbow DQNæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_ddpg_model(self, checkpoint):
        """åŠ è½½DDPGæ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from ddpg import DDPG, Actor, Critic, ActionConverter
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“
                agent = DDPG(config['state_dim'], config['action_dim'], config['action_space_config'])
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                agent.critic.load_state_dict(checkpoint['critic_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.actor.eval()
                agent.critic.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from ddpg import RunningStats
                    running_stats = RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint.get('running_stats_std', checkpoint.get('running_stats_var', 1.0))
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ DDPGæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ DDPGæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_td3_model(self, checkpoint):
        """åŠ è½½TD3æ¨¡å‹"""
        try:
            # ç›´æ¥ä½¿ç”¨è½»é‡çº§æ¨ç†å°è£…ï¼Œé¿å…å¯¼å…¥TD3æ¨¡å—å¼•å‘çš„å¡é¡¿
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # è½»é‡ç‰ˆåŠ¨ä½œè½¬æ¢å™¨ï¼ˆä¸TD3ä¸€è‡´çš„æ˜ å°„ï¼‰
                class _TD3ActionConverter:
                    def __init__(self, action_space_config):
                        self.action_map = action_space_config
                    def _convert_single(self, value, options):
                        scaled = (value + 1) / 2
                        idx = int(round(scaled * (len(options) - 1)))
                        return options[max(0, min(idx, len(options) - 1))]
                    def continuous_to_discrete(self, continuous_action):
                        return {
                            'ev_power': self._convert_single(continuous_action[0], self.action_map['ev_power']),
                            'battery_power': self._convert_single(continuous_action[1], self.action_map['battery_power']),
                            'wash_machine_schedule': self._convert_single(continuous_action[2], self.action_map['wash_machine_schedule']),
                            'Air_conditioner_set_temp': self._convert_single(continuous_action[3], self.action_map['Air_conditioner_set_temp']),
                            'Air_conditioner_set_temp2': self._convert_single(continuous_action[4], self.action_map['Air_conditioner_set_temp2']),
                            'ewh_set_temp': self._convert_single(continuous_action[5], self.action_map['ewh_set_temp'])
                        }

                # è½»é‡ç‰ˆç½‘ç»œç»“æ„ï¼ˆä¸TD3ä¸­Actorä¿æŒä¸€è‡´ï¼‰
                class _TD3Actor(torch.nn.Module):
                    def __init__(self, state_dim, action_dim):
                        super().__init__()
                        self.net = torch.nn.Sequential(
                            torch.nn.Linear(state_dim, 512),
                            torch.nn.ReLU(),
                            torch.nn.Linear(512, 256),
                            torch.nn.ReLU(),
                            torch.nn.Linear(256, action_dim)
                        )
                    def forward(self, state):
                        return self.net(state)

                class _TD3Agent:
                    def __init__(self, state_dim, action_dim, action_space_config):
                        self.actor = _TD3Actor(state_dim, action_dim)
                        self.converter = _TD3ActionConverter(action_space_config)

                agent = _TD3Agent(config['state_dim'], config['action_dim'], config['action_space_config'])

                # åŠ è½½æƒé‡ï¼ˆä»…æ¨ç†æ‰€éœ€ï¼‰
                agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                agent.actor.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    # è½»é‡ç‰ˆRunningStats
                    class _RunningStats:
                        def __init__(self, shape):
                            self.mean = np.zeros(shape, dtype=np.float32)
                            self.std = np.ones(shape, dtype=np.float32)
                            self.count = 1.0
                        def normalize(self, x):
                            return (x - self.mean) / (self.std + 1e-8)
                    running_stats = _RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint.get('running_stats_std', checkpoint.get('running_stats_var', 1.0))
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ TD3æ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ TD3æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_sac_model(self, checkpoint):
        """åŠ è½½SACæ¨¡å‹"""
        try:
            print("   ğŸ”§ SAC: è¿›å…¥è½»é‡åŠ è½½é€»è¾‘")
            # ä½¿ç”¨è½»é‡çº§æ¨ç†å°è£…ï¼Œé¿å…å¯¼å…¥sac2æ¨¡å—å¼•å‘çš„å¡é¡¿
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                print(f"   ğŸ”§ SAC: è¯»å–training_config: state_dim={config.get('state_dim')}, action_dim={config.get('action_dim')}")
                
                # è½»é‡ç‰ˆSACçš„ç»„ä»¶ï¼ˆä¸sac2ä¿æŒä¸€è‡´çš„æ¨ç†æ¥å£ï¼‰
                class _SACActionConverter:
                    def __init__(self):
                        self.action_map = {
                            'ev_power': [-6.6, -3.3, 0, 3.3, 6.6],
                            'battery_power': [-4.4, -2.2, 0, 2.2, 4.4],
                            'wash_machine_schedule': [0, 1, 2, 3, 4, 5, 6],
                            'Air_conditioner_set_temp': [16, 18, 20, 22, 24, 26, 28, 30],
                            'Air_conditioner_set_temp2': [16, 18, 20, 22, 24, 26, 28, 30],
                            'ewh_set_temp': [40, 45, 50, 55, 60, 65, 70]
                        }
                    def _convert_single(self, value, options):
                        scaled = (value + 1) / 2
                        idx = int(round(scaled * (len(options) - 1)))
                        return options[max(0, min(idx, len(options) - 1))]
                    def continuous_to_discrete(self, continuous_action):
                        return {
                            'ev_power': self._convert_single(continuous_action[0], self.action_map['ev_power']),
                            'battery_power': self._convert_single(continuous_action[1], self.action_map['battery_power']),
                            'wash_machine_schedule': self._convert_single(continuous_action[2], self.action_map['wash_machine_schedule']),
                            'Air_conditioner_set_temp': self._convert_single(continuous_action[3], self.action_map['Air_conditioner_set_temp']),
                            'Air_conditioner_set_temp2': self._convert_single(continuous_action[4], self.action_map['Air_conditioner_set_temp2']),
                            'ewh_set_temp': self._convert_single(continuous_action[5], self.action_map['ewh_set_temp'])
                        }

                # ä»æƒé‡ä¸­æ¨æ–­éšè—ç»´åº¦ï¼Œä¿è¯ç»“æ„å¯¹é½
                try:
                    inferred_hidden = checkpoint['actor_state_dict']['net.0.weight'].shape[0]
                except Exception:
                    inferred_hidden = config.get('hidden_dim', 512)

                class _SACActor(torch.nn.Module):
                    def __init__(self, state_dim, action_dim, hidden_dim):
                        super().__init__()
                        self.net = torch.nn.Sequential(
                            torch.nn.Linear(state_dim, hidden_dim),
                            torch.nn.LayerNorm(hidden_dim),
                            torch.nn.ReLU(),
                            torch.nn.Linear(hidden_dim, hidden_dim),
                            torch.nn.LayerNorm(hidden_dim),
                            torch.nn.ReLU()
                        )
                        self.mean = torch.nn.Linear(hidden_dim, action_dim)
                        self.log_std = torch.nn.Linear(hidden_dim, action_dim)
                        # ä¸è®­ç»ƒç«¯ä¸€è‡´ï¼šä¸æŠŠ action_scale/bias ä½œä¸º state_dict çš„ä¸€éƒ¨åˆ†
                        self.action_scale = torch.tensor([1.0] * action_dim)
                        self.action_bias = torch.tensor([0.0] * action_dim)
                    def forward(self, state):
                        x = self.net(state)
                        mean = self.mean(x)
                        log_std = self.log_std(x)
                        log_std = torch.clamp(log_std, min=-20, max=2)
                        return mean, log_std
                    def sample(self, state):
                        mean, log_std = self.forward(state)
                        std = torch.exp(log_std)
                        normal = torch.distributions.Normal(mean, std)
                        x_t = normal.rsample()
                        y_t = torch.tanh(x_t)
                        action = y_t * self.action_scale + self.action_bias
                        log_prob = normal.log_prob(x_t)
                        log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)
                        return action, log_prob.sum(1, keepdim=True)

                class _SACAgent:
                    def __init__(self, state_dim, action_dim):
                        self.actor = _SACActor(state_dim, action_dim, inferred_hidden)
                        self.converter = _SACActionConverter()
                    def select_action(self, state_tensor):
                        with torch.no_grad():
                            if isinstance(state_tensor, np.ndarray):
                                state_tensor = torch.FloatTensor(state_tensor).unsqueeze(0)
                            action_cont, _ = self.actor.sample(state_tensor)
                        return self.converter.continuous_to_discrete(action_cont.cpu().numpy()[0])

                print("   ğŸ”§ SAC: æ„å»ºè½»é‡Actor")
                agent = _SACAgent(config['state_dim'], config['action_dim'])
                print("   ğŸ”§ SAC: åŠ è½½actor_state_dict")
                agent.actor.load_state_dict(checkpoint['actor_state_dict'], strict=True)
                print("   ğŸ”§ SAC: è®¾ç½®evalæ¨¡å¼")
                agent.actor.eval()
                
                return {
                    'agent': agent,
                    'running_stats': None,  # SACé€šå¸¸ä¸ä½¿ç”¨è¿è¡Œç»Ÿè®¡
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ SACæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ SACæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def get_carbon_intensity(self, electricity_price):
        """æ ¹æ®ç”µä»·è·å–å¯¹åº”çš„ç¢³å¼ºåº¦"""
        if electricity_price <= 0.2:  # ä½è°·æœŸ
            return self.carbon_intensity_mapping['low_valley']
        elif electricity_price >= 0.8:  # é«˜å³°æœŸ
            return self.carbon_intensity_mapping['peak']
        else:  # å¹³æ®µæœŸ
            return self.carbon_intensity_mapping['flat']
    
    def get_random_action(self, state, env):
        """ç”ŸæˆéšæœºåŠ¨ä½œï¼ˆä½¿ç”¨ç¯å¢ƒçš„åŠ¨ä½œæ©ç ï¼‰"""
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # æ ¹æ®æ©ç éšæœºé€‰æ‹©æœ‰æ•ˆåŠ¨ä½œ
        action = {}
        
        # EVåŠŸç‡é€‰æ‹©
        ev_valid_indices = [i for i, valid in enumerate(action_mask['ev_power']) if valid]
        if ev_valid_indices:
            ev_idx = random.choice(ev_valid_indices)
            action['ev_power'] = env.action_space['ev_power'][ev_idx]
        else:
            action['ev_power'] = 0
        
        # ESSåŠŸç‡é€‰æ‹©
        ess_valid_indices = [i for i, valid in enumerate(action_mask['battery_power']) if valid]
        if ess_valid_indices:
            ess_idx = random.choice(ess_valid_indices)
            action['battery_power'] = env.action_space['battery_power'][ess_idx]
        else:
            action['battery_power'] = 0
        
        # å…¶ä»–è®¾å¤‡éšæœºé€‰æ‹©
        action['wash_machine_schedule'] = random.choice(env.action_space['wash_machine_schedule'])
        action['Air_conditioner_set_temp'] = random.choice(env.action_space['Air_conditioner_set_temp'])
        action['Air_conditioner_set_temp2'] = random.choice(env.action_space['Air_conditioner_set_temp2'])
        action['ewh_set_temp'] = random.choice(env.action_space['ewh_set_temp'])
        
        return action
    
    def get_model_action(self, state, env, strategy_key='proposed_rl'):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è·å–åŠ¨ä½œï¼ˆä½¿ç”¨ç¯å¢ƒçš„åŠ¨ä½œæ©ç ï¼‰"""
        model = self.loaded_models.get(strategy_key)
        if model is None:
            raise ValueError(f"âŒ {strategy_key} æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•æ‰§è¡Œæ¨¡å‹åŠ¨ä½œ")
        
        try:
            if strategy_key == 'proposed_rl':
                action = self.get_ppo_action(state, env, model)
            elif strategy_key == 'rainbow_dqn':
                action = self.get_rainbow_dqn_action(state, env, model)
            elif strategy_key == 'ddpg':
                action = self.get_ddpg_action(state, env, model)
            elif strategy_key == 'td3':
                action = self.get_td3_action(state, env, model)
            elif strategy_key == 'sac':
                action = self.get_sac_action(state, env, model)
            else:
                raise ValueError(f"âŒ æœªçŸ¥çš„ç­–ç•¥ç±»å‹: {strategy_key}")
            
            # æ£€æŸ¥åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            if action is None:
                raise ValueError(f"âŒ {strategy_key} æ¨¡å‹è¿”å›NoneåŠ¨ä½œï¼Œæ¨¡å‹æ¨ç†å¤±è´¥")
            
            return action
                
        except Exception as e:
            print(f"âŒ {strategy_key} æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…çŸ¥é“çœŸæ­£çš„é—®é¢˜
    
    def get_ppo_action(self, state, env, model):
        """è·å–PPOæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.shared_backbone.to('cpu').float()
        for branch in agent.actor_branches.values():
            branch.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨æ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¼ å…¥åŠ¨ä½œæ©ç ï¼‰
        with torch.no_grad():
            action_result = agent.take_action(normalized_state, action_mask)
            action_dict = action_result[0]  # å–actionså­—å…¸
            
            # éªŒè¯åŠ¨ä½œå­—å…¸çš„æœ‰æ•ˆæ€§
            if not isinstance(action_dict, dict):
                raise ValueError(f"âŒ PPOæ¨¡å‹è¿”å›äº†æ— æ•ˆçš„åŠ¨ä½œæ ¼å¼: {type(action_dict)}")
            
            # æ£€æŸ¥å¿…è¦çš„åŠ¨ä½œé”®æ˜¯å¦å­˜åœ¨
            required_keys = ['ev_power', 'battery_power', 'wash_machine_schedule', 
                           'Air_conditioner_set_temp', 'Air_conditioner_set_temp2', 'ewh_set_temp']
            for key in required_keys:
                if key not in action_dict:
                    raise ValueError(f"âŒ PPOåŠ¨ä½œå­—å…¸ç¼ºå°‘å¿…è¦çš„é”®: {key}")
        
        return action_dict
    
    def get_rainbow_dqn_action(self, state, env, model):
        """è·å–Rainbow DQNæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.shared_backbone.to('cpu').float()
        for branch in agent.q_branches.values():
            branch.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨DQNæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¼ å…¥åŠ¨ä½œæ©ç ï¼Œä¸æ¢ç´¢ï¼‰
        with torch.no_grad():
            action_dict = agent.select_action(normalized_state.cpu(), action_mask, explore=False)
        
        return action_dict
    
    def get_ddpg_action(self, state, env, model):
        """è·å–DDPGæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        agent.critic.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨DDPGæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            continuous_action = agent.actor(normalized_state).cpu().numpy().flatten()
            # ä½¿ç”¨åŠ¨ä½œè½¬æ¢å™¨å°†è¿ç»­åŠ¨ä½œè½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œ
            action_dict = agent.converter.continuous_to_discrete(continuous_action)
            
            # éªŒè¯åŠ¨ä½œå­—å…¸çš„æœ‰æ•ˆæ€§
            if not isinstance(action_dict, dict):
                raise ValueError(f"âŒ DDPGåŠ¨ä½œè½¬æ¢å™¨è¿”å›äº†æ— æ•ˆçš„åŠ¨ä½œæ ¼å¼: {type(action_dict)}")
            
            # æ£€æŸ¥å¿…è¦çš„åŠ¨ä½œé”®æ˜¯å¦å­˜åœ¨
            required_keys = ['ev_power', 'battery_power', 'wash_machine_schedule', 
                           'Air_conditioner_set_temp', 'Air_conditioner_set_temp2', 'ewh_set_temp']
            for key in required_keys:
                if key not in action_dict:
                    raise ValueError(f"âŒ DDPGåŠ¨ä½œå­—å…¸ç¼ºå°‘å¿…è¦çš„é”®: {key}")
        
        return action_dict
    
    def get_td3_action(self, state, env, model):
        """è·å–TD3æ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨TD3æ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            continuous_action = agent.actor(normalized_state).cpu().numpy().flatten()
            # ä½¿ç”¨åŠ¨ä½œè½¬æ¢å™¨å°†è¿ç»­åŠ¨ä½œè½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œ
            action_dict = agent.converter.continuous_to_discrete(continuous_action)
        
        return action_dict
    
    def get_sac_action(self, state, env, model):
        """è·å–SACæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        state_tensor = state_tensor.float()
        
        # ä½¿ç”¨SACæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            action_dict = agent.select_action(state_tensor)
        
        return action_dict
    
    def state_to_vector(self, state, state_keys):
        """å°†çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºå‘é‡"""
        if state_keys:
            state_vector = [state[k] for k in state_keys]
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰å­—æ¯é¡ºåºæ’åº
            ordered_keys = sorted(state.keys())
            state_vector = [state[k] for k in ordered_keys]
        return state_vector
    
    def apply_device_mask(self, action, mask_type):
        """åº”ç”¨è®¾å¤‡æ©ç ï¼ˆå‚¨èƒ½è®¾å¤‡çš„å¯ç”¨/ç¦ç”¨ï¼‰"""
        masked_action = action.copy()
        
        # ä¸ºç¡®ä¿æ§åˆ¶å˜é‡ä¸¥æ ¼æ€§ï¼ŒåŸºç¡€ç”¨ç”µè®¾å¤‡ä½¿ç”¨å›ºå®šç­–ç•¥
        masked_action['Air_conditioner_set_temp'] = 24     # å›ºå®šæ¸©åº¦
        masked_action['Air_conditioner_set_temp2'] = 24    # å›ºå®šæ¸©åº¦
        masked_action['ewh_set_temp'] = 55                 # å›ºå®šæ¸©åº¦
        
        if mask_type == 'baseline':
            # å¯¹ç…§ç»„ï¼šç¦ç”¨å‚¨èƒ½åŠŸèƒ½
            masked_action['battery_power'] = 0
            if masked_action['ev_power'] < 0:
                masked_action['ev_power'] = 0
                
        elif mask_type == 'v2g_only':
            # V2Gç»„ï¼šéƒ¨åˆ†å‚¨èƒ½åŠŸèƒ½
            masked_action['battery_power'] = 0
            
        elif mask_type == 'full':
            # å®Œæ•´ä¼˜åŒ–ç»„ï¼šå…è®¸æ‰€æœ‰åŠŸèƒ½
            pass
        
        return masked_action
    
    def calculate_home_total_carbon(self, env, electricity_price):
        """è®¡ç®—å®¶åº­æ€»è´Ÿè·çš„ç¢³æ’æ”¾"""
        carbon_intensity = self.get_carbon_intensity(electricity_price)
        
        # è·å–å®¶åº­æ€»è´Ÿè·
        total_home_load = env.total_load_compute()
        
        # åªæœ‰å‡€è´­ç”µæ‰äº§ç”Ÿç¢³æ’æ”¾
        if total_home_load > 0:  # å®¶åº­éœ€è¦ä»ç”µç½‘è´­ç”µ
            step_carbon = total_home_load * 0.5 * carbon_intensity
            grid_purchase = total_home_load * 0.5
            grid_sale = 0
        else:  # å®¶åº­å‘ç”µç½‘å”®ç”µæˆ–å¹³è¡¡
            step_carbon = 0
            grid_purchase = 0
            grid_sale = abs(total_home_load) * 0.5
        
        return step_carbon, grid_purchase, grid_sale, carbon_intensity, total_home_load
    
    def run_single_episode(self, strategy_key, config_key, episode_num):
        """è¿è¡Œå•ä¸ªepisode"""
        env = HomeEnergyManagementEnv()
        state = env.reset()
        
        strategy_config = self.strategies[strategy_key]
        config = self.configurations[config_key]
        
        # åˆå§‹åŒ–episodeæ•°æ®è®°å½•
        episode_data = {
            'episode': episode_num,
            'strategy': strategy_config['name'],
            'configuration': config['name'],
            'total_carbon': 0,
            'total_cost': 0,
            'total_grid_purchase': 0,
            'total_grid_sale': 0,
            'ev_charge_energy': 0,
            'ev_discharge_energy': 0,
            'ess_charge_energy': 0,
            'ess_discharge_energy': 0,
            'vehicle_storage_actions': 0,
            'battery_storage_actions': 0,
            'carbon_intensity_avg': 0,
            'home_load_avg': 0,
            'comfort_score_sum': 0,
            'high_carbon_purchase': 0,  # é«˜ç¢³æ—¶æ®µè´­ç”µé‡
            'low_carbon_purchase': 0,   # ä½ç¢³æ—¶æ®µè´­ç”µé‡
            'ev_initial_soc': state['ev_battery_state'] / 24,
            'ess_initial_soc': state['ess_state'] / 24,
            'ev_final_soc': 0,
            'ess_final_soc': 0
        }
        
        for step in range(self.episode_length):
            # è·å–ç­–ç•¥åŠ¨ä½œ
            if strategy_key == 'random':
                raw_action = self.get_random_action(state, env)
            else:
                try:
                    raw_action = self.get_model_action(state, env, strategy_key)
                except Exception as e:
                    print(f"âŒ Episode {episode_num}, Step {step}: {strategy_key} æ¨¡å‹å¤±è´¥: {e}")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œåœæ­¢å®éªŒ
            
            # åº”ç”¨è®¾å¤‡æ©ç 
            action = self.apply_device_mask(raw_action, config['mask_type'])
            
            # æ‰§è¡ŒåŠ¨ä½œï¼Œæ›´æ–°ç¯å¢ƒçŠ¶æ€
            next_state, reward, done = env.step(state, action)
            
            # è®¡ç®—å½“å‰æ­¥éª¤çš„å®¶åº­æ€»ç¢³æ’æ”¾
            step_carbon, grid_purchase, grid_sale, carbon_intensity, total_home_load = self.calculate_home_total_carbon(
                env, state['electricity_price']
            )
            
            # è®°å½•ç¢³æ’æ”¾å’Œç”µç½‘äº¤äº’æ•°æ®
            episode_data['total_carbon'] += step_carbon
            episode_data['total_grid_purchase'] += grid_purchase
            episode_data['total_grid_sale'] += grid_sale
            episode_data['carbon_intensity_avg'] += carbon_intensity
            episode_data['home_load_avg'] += abs(total_home_load)

            # æˆæœ¬ï¼ˆæŒ‰è´­ç”µé‡ä¸ç”µä»·è®¡ä»·ï¼›grid_purchase å·²å«0.5hæ­¥é•¿ç³»æ•°ï¼‰
            step_cost = grid_purchase * state['electricity_price']
            episode_data['total_cost'] += step_cost
            
            # è®°å½•é«˜ç¢³/ä½ç¢³æ—¶æ®µçš„è´­ç”µé‡
            if carbon_intensity >= 0.9:  # é«˜ç¢³æ—¶æ®µ
                episode_data['high_carbon_purchase'] += grid_purchase
            elif carbon_intensity <= 0.3:  # ä½ç¢³æ—¶æ®µ
                episode_data['low_carbon_purchase'] += grid_purchase
            
            # è®°å½•èƒ½é‡æ•°æ®
            if action['ev_power'] > 0:
                episode_data['ev_charge_energy'] += action['ev_power'] * 0.5
            elif action['ev_power'] < 0:
                episode_data['ev_discharge_energy'] += abs(action['ev_power']) * 0.5
                episode_data['vehicle_storage_actions'] += 1
            
            if action['battery_power'] > 0:
                episode_data['ess_charge_energy'] += action['battery_power'] * 0.5
            elif action['battery_power'] < 0:
                episode_data['ess_discharge_energy'] += abs(action['battery_power']) * 0.5
                episode_data['battery_storage_actions'] += 1
            
            # æ›´æ–°çŠ¶æ€
            state = next_state

            # èˆ’é€‚åº¦ï¼ˆåŸºäºå®¤æ¸©åå¥½ä¸çƒ­æ°´æ¸©åº¦èŒƒå›´çš„ç®€å•æŒ‡æ ‡ï¼‰
            try:
                temp_diff1 = abs(state.get('indoor_temp', 24) - state.get('user_temp_preference', 24))
                temp_diff2 = abs(state.get('indoor_temp2', 24) - state.get('user_temp_preference2', 24))
                temp_comfort1 = max(0, 1 - max(0, temp_diff1 - 2) / 8)
                temp_comfort2 = max(0, 1 - max(0, temp_diff2 - 2) / 8)

                ewh_temp = state.get('ewh_temp', 50)
                hour = int(state.get('time_index', 0) // 2)
                if 6 <= hour <= 9 or 18 <= hour <= 22:
                    low_temp, high_temp = 50, 60
                else:
                    low_temp, high_temp = 40, 50
                if low_temp <= ewh_temp <= high_temp:
                    ewh_temp_comfort = 1.0
                else:
                    deviation = max(low_temp - ewh_temp, ewh_temp - high_temp)
                    ewh_temp_comfort = max(0, 1 - deviation / 10)

                comfort_step = (temp_comfort1 + temp_comfort2 + ewh_temp_comfort) / 3.0
                episode_data['comfort_score_sum'] += comfort_step
            except Exception:
                pass
        
        # è®°å½•æœ€ç»ˆSOC
        episode_data['ev_final_soc'] = state['ev_battery_state'] / 24
        episode_data['ess_final_soc'] = state['ess_state'] / 24
        
        # è®¡ç®—å¹³å‡å€¼
        episode_data['carbon_intensity_avg'] /= self.episode_length
        episode_data['home_load_avg'] /= self.episode_length
        episode_data['comfort_score_avg'] = episode_data['comfort_score_sum'] / self.episode_length
        
        return episode_data
    
    def run_experiment_group(self, strategy_key, config_key):
        """è¿è¡Œä¸€ç»„å®éªŒ"""
        strategy_name = self.strategies[strategy_key]['name']
        config_name = self.configurations[config_key]['name']
        group_key = f"{strategy_key}_{config_key}"
        
        print(f"ğŸ”„ æ­£åœ¨è¿è¡Œ {strategy_name} - {config_name}...")
        
        results = []
        for episode in range(self.num_episodes):
            episode_data = self.run_single_episode(strategy_key, config_key, episode)
            results.append(episode_data)
        
        self.results[group_key] = results
        print(f"âœ… {strategy_name} - {config_name} å®Œæˆ")
        
        return results
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒ...")
        
        # è¿è¡Œæ‰€æœ‰ç­–ç•¥å’Œé…ç½®çš„ç»„åˆ
        for strategy_key in self.strategies.keys():
            for config_key in self.configurations.keys():
                self.run_experiment_group(strategy_key, config_key)
        
        print("\nğŸ‰ æ‰€æœ‰å®éªŒç»„å®Œæˆï¼")
    
    def analyze_results(self):
        """åˆ†æå®éªŒç»“æœ"""
        # è½¬æ¢ä¸ºDataFrame
        all_results = []
        for group_key, results in self.results.items():
            for result in results:
                result['group_key'] = group_key
                all_results.append(result)
        
        df_all = pd.DataFrame(all_results)
        
        # è®¡ç®—å„ç»„å¹³å‡å€¼
        results_summary = {}
        for group_key, results in self.results.items():
            df = pd.DataFrame(results)
            results_summary[group_key] = {
                'avg_carbon': df['total_carbon'].mean(),
                'avg_cost': df['total_cost'].mean(),
                'avg_grid_purchase': df['total_grid_purchase'].mean(),
                'avg_grid_sale': df['total_grid_sale'].mean(),
                'avg_ev_charge': df['ev_charge_energy'].mean(),
                'avg_ev_discharge': df['ev_discharge_energy'].mean(),
                'avg_ess_charge': df['ess_charge_energy'].mean(),
                'avg_ess_discharge': df['ess_discharge_energy'].mean(),
                'avg_high_carbon_purchase': df['high_carbon_purchase'].mean(),
                'avg_low_carbon_purchase': df['low_carbon_purchase'].mean(),
                'avg_vehicle_storage_actions': df['vehicle_storage_actions'].mean(),
                'avg_battery_storage_actions': df['battery_storage_actions'].mean(),
                'avg_comfort': df['comfort_score_avg'].mean(),
                'strategy': df['strategy'].iloc[0],
                'configuration': df['configuration'].iloc[0]
            }
        
        # æ‰“å°ç»“æœåˆ†æ
        print(f"\n{'='*70}")
        print(f"ğŸ“Š ç®—æ³•ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒç»“æœåˆ†æ")
        print(f"{'='*70}")
        
        # å„ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”
        print(f"\nğŸ” å®Œæ•´é…ç½®ä¸‹å„ç®—æ³•ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”ï¼š")
        print(f"{'ç®—æ³•ç­–ç•¥':<20} {'å¹³å‡ç¢³æ’æ”¾(kg CO2)':<20}")
        print(f"{'-'*45}")
        
        carbon_data = {}
        for strategy_key, strategy in self.strategies.items():
            group_key = f"{strategy_key}_full_optimization"
            if group_key in results_summary:
                summary = results_summary[group_key]
                carbon_data[strategy['name']] = summary['avg_carbon']
                print(f"{strategy['name']:<20} {summary['avg_carbon']:<20.2f}")
        
        # è¯¦ç»†çš„ç¢³æ’æ”¾å¯¹æ¯”æ•°æ®æ‰“å°
        print(f"\nğŸ“Š è¯¦ç»†ç¢³æ’æ”¾å¯¹æ¯”æ•°æ®:")
        for strategy_name, carbon_value in carbon_data.items():
            print(f"  {strategy_name}: {carbon_value:.4f} kg CO2")
        
        # å¦‚æœæœ‰éšæœºç­–ç•¥ï¼Œè®¡ç®—æ”¹è¿›å¹…åº¦
        if 'random' in [k for k in self.strategies.keys()]:
            random_key = "random_full_optimization"
            if random_key in results_summary:
                random_carbon = results_summary[random_key]['avg_carbon']
                print(f"\nğŸ“ˆ ç›¸å¯¹éšæœºç­–ç•¥çš„æ”¹è¿›:")
                print(f"  éšæœºç­–ç•¥åŸºå‡†: {random_carbon:.4f} kg CO2")
                
                for strategy_key, strategy in self.strategies.items():
                    if strategy_key != 'random':
                        model_key = f"{strategy_key}_full_optimization"
                        if model_key in results_summary:
                            model_carbon = results_summary[model_key]['avg_carbon']
                            improvement = random_carbon - model_carbon
                            improvement_pct = (improvement / random_carbon * 100) if random_carbon > 0 else 0
                            print(f"  {strategy['name']}: å‡å°‘ {improvement:.4f} kg CO2 ({improvement_pct:.2f}%)")

        
        return results_summary, df_all
    
    def create_visualization(self, results_summary):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨ï¼šåˆ†åˆ«ç»˜åˆ¶ç¢³æ’æ”¾ã€æˆæœ¬ã€æ»¡æ„åº¦ï¼ˆå„ä¸€å¼ å›¾ï¼‰"""
        plt.style.use('default')
        strategies = list(self.strategies.keys())
        # å›ºå®šé…è‰²æ˜ å°„ï¼ˆæœ€åˆé…è‰²é£æ ¼ï¼Œä¸”ä¸æ¨¡å‹åç§°ä¸€ä¸€å¯¹åº”ï¼‰
        color_map = {
            'random': '#FF6B6B',      # Random
            'proposed_rl': '#4ECDC4', # PPO (Proposed RL)
            'rainbow_dqn': '#45B7D1', # Rainbow DQN
            'ddpg': '#96CEB4',        # DDPG
            'td3': '#FECA57',         # TD3
            'sac': '#9B59B6',         # SAC
        }
        default_color = '#34495E'

        # æŠ½å–æ•°æ®
        names, carbons, costs, comforts, colors = [], [], [], [], []
        for i, strategy_key in enumerate(strategies):
            group_key = f"{strategy_key}_full_optimization"
            if group_key not in results_summary:
                continue
            summary = results_summary[group_key]
            names.append({
                'random': 'Random',
                'proposed_rl': 'Proposed RL',
                'rainbow_dqn': 'Rainbow DQN',
                'ddpg': 'DDPG',
                'td3': 'TD3',
                'sac': 'SAC',
            }.get(strategy_key, strategy_key.upper()))
            carbons.append(summary.get('avg_carbon', 0.0))
            costs.append(summary.get('avg_cost', 0.0))
            comforts.append(summary.get('avg_comfort', 0.0))
            colors.append(color_map.get(strategy_key, default_color))

        x = np.arange(len(names))

        def draw_bar(values, ylabel, title, filename, ylim=None):
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            bars = ax.bar(x, values, color=colors, alpha=0.85, edgecolor='black', width=0.6)
            for bar in bars:
                h = bar.get_height()
                if h >= 0:
                    ax.text(bar.get_x() + bar.get_width()/2., h + max(h * 0.01, 1e-6), f'{h:.2f}', ha='center', va='bottom', fontsize=11)
            ax.set_ylabel(ylabel, fontweight='bold', fontsize=12)
            ax.set_title(title, fontweight='bold', fontsize=16)
            ax.set_xticks(x)
            ax.set_xticklabels(names, fontsize=11)
            ax.grid(True, alpha=0.3, axis='y')
            if ylim is not None:
                ax.set_ylim(*ylim)
            elif values:
                ax.set_ylim(0, max(values) * 1.1 if max(values) > 0 else 1)
            plt.tight_layout()
            figures_dir = os.path.join(self.project_root, 'figures', 'experiment_results')
            os.makedirs(figures_dir, exist_ok=True)
            path = os.path.join(figures_dir, filename)
            plt.savefig(path, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º: {filename}")

        # åˆ†åˆ«ç»˜åˆ¶ä¸‰å¼ å›¾
        draw_bar(carbons, 'Carbon (kg CO2)', 'Carbon Emissions', 'strategy_carbon.png')
        draw_bar(costs, 'Cost', 'Energy Cost', 'strategy_cost.png')
        draw_bar(comforts, 'Comfort (0-1)', 'User Comfort', 'strategy_comfort.png', ylim=(0, 1.05))
    
    def save_results(self, results_summary):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç¡®ä¿resultsç›®å½•å­˜åœ¨
        results_dir = os.path.join(self.project_root, 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        for group_key, results in self.results.items():
            df = pd.DataFrame(results)
            df.to_csv(os.path.join(results_dir, f'{group_key}_strategy_comparison_{timestamp}.csv'), index=False)
        
        # ä¿å­˜å¯¹æ¯”åˆ†æç»“æœ
        summary_df = pd.DataFrame(results_summary).T
        summary_df.to_csv(os.path.join(results_dir, f'strategy_comparison_summary_{timestamp}.csv'))
        
        print(f"\nğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜åˆ° ../results/ ç›®å½•")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå®éªŒå¯¹è±¡
    experiment = StrategyCarbonComparison()
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    experiment.run_all_experiments()
    
    # åˆ†æç»“æœ
    results_summary, df_all = experiment.analyze_results()
    
    # åˆ›å»ºå¯è§†åŒ–
    experiment.create_visualization(results_summary)
    
    # ä¿å­˜ç»“æœ
    experiment.save_results(results_summary)

if __name__ == "__main__":
    main()
