"""
ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒ
ç›®æ ‡ï¼šå¯¹æ¯”ä¸åŒç­–ç•¥ï¼ˆéšæœºç­–ç•¥ã€å„ç§è®­ç»ƒæ¨¡å‹ï¼‰åœ¨ä¸åŒé…ç½®ä¸‹çš„ç¢³æ’æ”¾æ•ˆæœ
æ”¯æŒæ‰©å±•ï¼šå¯ä»¥è½»æ¾æ·»åŠ æ›´å¤šç®—æ³•æ¨¡å‹è¿›è¡Œå¯¹æ¯”
"""
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)
# æ·»åŠ modelç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(project_root, 'model'))

from environment import HomeEnergyManagementEnv
import random
from datetime import datetime
import warnings

# è®¾ç½®matplotlibåç«¯å’Œè­¦å‘Š
warnings.filterwarnings('ignore')  # å¿½ç•¥è­¦å‘Š
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt

# è®¾ç½®å­—ä½“ä¸ºæ”¯æŒè‹±æ–‡çš„å­—ä½“
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class StrategyCarbonComparison:
    def __init__(self):
        # ç¢³å¼ºåº¦å› å­è®¾ç½®
        self.carbon_intensity_mapping = {
            'low_valley': 0.3,    # ä½è°·æœŸï¼šæ¸…æ´èƒ½æºä¸»å¯¼  
            'flat': 0.6,          # å¹³æ®µæœŸï¼šæ¸…æ´èƒ½æºä¸ç«ç”µæ··åˆ  kgCO2/kWh
            'peak': 0.9           # é«˜å³°æœŸï¼šç«ç”µä¸»å¯¼  kgCO2/kWh
        }
        
        # å®éªŒå‚æ•°
        self.num_episodes = 10
        self.episode_length = 336  # 7å¤©
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        self.project_root = os.path.dirname(self.current_dir)
        model_dir = os.path.join(self.project_root, 'model', 'saved_models')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(model_dir, exist_ok=True)
        
        # ç­–ç•¥é…ç½®ï¼šæ”¯æŒæ‰©å±•å¤šç§ç­–ç•¥
        self.strategies = {
            'random': {
                'name': 'éšæœºç­–ç•¥',
                'model_path': None,
                'strategy_func': self.get_random_action
            },
            'proposed_rl': {
                'name': 'PPOç®—æ³•',
                'model_path': os.path.join(model_dir, 'proposed_rl.pth'),
                'strategy_func': self.get_model_action
            },
            'rainbow_dqn': {
                'name': 'Rainbow DQN',
                'model_path': os.path.join(model_dir, 'rainbow_dqn_model_20250805_022938_norm.pth'),
                'strategy_func': self.get_model_action
            },
            'ddpg': {
                'name': 'DDPGç®—æ³•',
                'model_path': os.path.join(model_dir, 'ddpg.pth'),
                'strategy_func': self.get_model_action
            }
            # 'td3': {
            #     'name': 'TD3ç®—æ³•',
            #     'model_path': os.path.join(model_dir, 'td3_model_20250805_004024.pth'),
            #     'strategy_func': self.get_model_action
            # },
            # 'sac': {
            #     'name': 'SACç®—æ³•',
            #     'model_path': os.path.join(model_dir, 'sac2_model_20250805_004024.pth'),
            #     'strategy_func': self.get_model_action
            # }
        }
        
        # å®éªŒé…ç½®ï¼šç»Ÿä¸€ä½¿ç”¨å®Œæ•´é…ç½®
        self.configurations = {
            'full_optimization': {
                'name': 'å®Œæ•´ä¼˜åŒ–é…ç½®',
                'mask_type': 'full'
            }
        }
        
        # ç»“æœå­˜å‚¨ï¼š{strategy}_{config} æ ¼å¼
        self.results = {}
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        self.loaded_models = {}
        self.load_all_models()
        
    def load_all_models(self):
        """åŠ è½½æ‰€æœ‰é…ç½®çš„æ¨¡å‹"""
        print("ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹...")
        for strategy_key, strategy_config in self.strategies.items():
            model_path = strategy_config['model_path']
            print(f"ğŸ“ æ£€æŸ¥ç­–ç•¥ {strategy_key}: è·¯å¾„ = {model_path}")
            
            if model_path and os.path.exists(model_path):
                print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹åŠ è½½ {strategy_config['name']} æ¨¡å‹...")
                model = self.load_model(model_path, strategy_key)
                self.loaded_models[strategy_key] = model
                if model:
                    print(f"âœ… {strategy_config['name']} æ¨¡å‹åŠ è½½æˆåŠŸ")
                else:
                    print(f"âŒ {strategy_config['name']} æ¨¡å‹åŠ è½½å¤±è´¥")
            else:
                self.loaded_models[strategy_key] = None
                if model_path:
                    print(f"âŒ {strategy_config['name']} æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºç›®å½•å†…å®¹
                    model_dir = os.path.dirname(model_path)
                    if os.path.exists(model_dir):
                        print(f"   ğŸ“‚ ç›®å½•å†…å®¹: {os.listdir(model_dir)}")
                    else:
                        print(f"   ğŸ“‚ ç›®å½•ä¸å­˜åœ¨: {model_dir}")
                else:
                    print(f"â„¹ï¸ {strategy_config['name']} æ— éœ€åŠ è½½æ¨¡å‹")
    
    def load_model(self, model_path, strategy_key):
        """åŠ è½½å•ä¸ªæ¨¡å‹ï¼ˆæ ¹æ®ç­–ç•¥ç±»å‹ï¼‰"""
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            
            if strategy_key == 'proposed_rl':
                return self.load_ppo_model(checkpoint)
            elif strategy_key == 'rainbow_dqn':
                return self.load_rainbow_dqn_model(checkpoint)
            elif strategy_key == 'ddpg':
                return self.load_ddpg_model(checkpoint)
            elif strategy_key == 'td3':
                return self.load_td3_model(checkpoint)
            elif strategy_key == 'sac':
                return self.load_sac_model(checkpoint)
            else:
                print(f"âš ï¸ æœªçŸ¥çš„ç­–ç•¥ç±»å‹: {strategy_key}")
                return None
                
        except Exception as e:
            print(f"âŒ {strategy_key} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_ppo_model(self, checkpoint):
        """åŠ è½½PPOæ¨¡å‹"""
        try:
            if isinstance(checkpoint, dict) and 'shared_backbone_state_dict' in checkpoint:
                # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
                model_path = os.path.join(self.project_root, 'model')
                if model_path not in sys.path:
                    sys.path.append(model_path)
                from PPO_3rd import HomeEnergyPPO
                
                # åˆ›å»ºç¯å¢ƒå®ä¾‹
                env = HomeEnergyManagementEnv()
                
                # ä»checkpointè·å–è®­ç»ƒé…ç½®
                training_config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºå®Œæ•´çš„æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨PPO_3rdçš„å‚æ•°ï¼‰
                agent = HomeEnergyPPO(
                    env=env,
                    state_dim=training_config['state_dim'],
                    hidden_dim=training_config['hidden_dim'],
                    action_space_config=training_config['action_space_config'],
                    gamma=training_config['gamma'],
                    lmbda=training_config['lmbda'],
                    eps=training_config['eps'],
                    epochs=training_config['epochs'],
                    ent_coef=training_config['ent_coef'],
                    max_grad_norm=training_config['max_grad_norm'],
                    device='cpu',
                    constraint_mode=training_config.get('constraint_mode', 'none'),
                    use_state_normalization=training_config.get('use_state_normalization', True),
                    use_advantage_normalization=True,
                    use_dynamic_mask=training_config.get('use_dynamic_mask', True),
                    constraint_config=training_config.get('constraint_config', None)
                )
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.shared_backbone.load_state_dict(checkpoint['shared_backbone_state_dict'])
                agent.actor_branches.load_state_dict(checkpoint['actor_branches_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.shared_backbone.eval()
                for branch in agent.actor_branches.values():
                    branch.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºçŠ¶æ€æ ‡å‡†åŒ–ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from PPO_3rd import RunningStats
                    running_stats = RunningStats(shape=training_config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint['running_stats_std']
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint['state_keys']
                }
            else:
                print("âŒ PPOæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                print(f"   æœŸæœ›çš„é”®: shared_backbone_state_dict")
                print(f"   å®é™…çš„é”®: {list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'éå­—å…¸ç±»å‹'}")
                return None
        except Exception as e:
            print(f"âŒ PPOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_rainbow_dqn_model(self, checkpoint):
        """åŠ è½½Rainbow DQNæ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from dqn import RainbowDQN
            
            # åˆ›å»ºç¯å¢ƒå®ä¾‹
            env = HomeEnergyManagementEnv()
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“ï¼ˆå¼ºåˆ¶ä½¿ç”¨CPUï¼‰
                import torch
                original_device = torch.cuda.current_device() if torch.cuda.is_available() else None
                
                agent = RainbowDQN(
                    state_dim=config['state_dim'],
                    hidden_dim=config['hidden_dim'],
                    action_space_config=config['action_space_config'],
                    lr=1e-4,  # ä½¿ç”¨é»˜è®¤å€¼ï¼Œå› ä¸ºæ¨¡å‹æ–‡ä»¶ä¸­æ²¡æœ‰ä¿å­˜è¿™äº›è®­ç»ƒå‚æ•°
                    gamma=config.get('gamma', 0.96),
                    tau=config.get('tau', 0.01),
                    buffer_size=100000,  # ä½¿ç”¨é»˜è®¤å€¼
                    batch_size=config.get('batch_size', 512),
                    epsilon_start=1.0,  # ä½¿ç”¨é»˜è®¤å€¼
                    epsilon_end=0.05,   # ä½¿ç”¨é»˜è®¤å€¼
                    epsilon_decay=0.995,  # ä½¿ç”¨é»˜è®¤å€¼
                    n_step=config.get('n_step', 3),
                    alpha=config.get('alpha', 0.6),
                    beta=config.get('beta', 0.4)
                )
                
                # ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½åœ¨CPUä¸Š
                agent.device = torch.device('cpu')
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.shared_backbone.load_state_dict(checkpoint['shared_backbone_state_dict'])
                agent.q_branches.load_state_dict(checkpoint['q_branches_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç¡®ä¿åœ¨CPUä¸Š
                agent.shared_backbone.eval()
                agent.shared_backbone.to('cpu')
                for branch in agent.q_branches.values():
                    branch.eval()
                    branch.to('cpu')
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from PPO_3rd import RunningStats
                    running_stats = RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint['running_stats_std']
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ Rainbow DQNæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ Rainbow DQNæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_ddpg_model(self, checkpoint):
        """åŠ è½½DDPGæ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from ddpg import DDPG, Actor, Critic, ActionConverter
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“
                agent = DDPG(config['state_dim'], config['action_dim'], config['action_space_config'])
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                agent.critic.load_state_dict(checkpoint['critic_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.actor.eval()
                agent.critic.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from ddpg import RunningStats
                    running_stats = RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint.get('running_stats_std', checkpoint.get('running_stats_var', 1.0))
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ DDPGæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ DDPGæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_td3_model(self, checkpoint):
        """åŠ è½½TD3æ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from TD3 import TD3, Actor, Critic, ActionConverter
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“
                agent = TD3(config['state_dim'], config['action_dim'], config['action_space_config'])
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                agent.critic1.load_state_dict(checkpoint['critic1_state_dict'])
                agent.critic2.load_state_dict(checkpoint['critic2_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.actor.eval()
                agent.critic1.eval()
                agent.critic2.eval()
                
                # åŠ è½½è¿è¡Œç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                running_stats = None
                if 'running_stats_mean' in checkpoint:
                    from TD3 import RunningStats
                    running_stats = RunningStats(shape=config['state_dim'])
                    running_stats.mean = checkpoint['running_stats_mean']
                    running_stats.std = checkpoint.get('running_stats_std', checkpoint.get('running_stats_var', 1.0))
                    running_stats.count = checkpoint['running_stats_count']
                
                return {
                    'agent': agent,
                    'running_stats': running_stats,
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ TD3æ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ TD3æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_sac_model(self, checkpoint):
        """åŠ è½½SACæ¨¡å‹"""
        try:
            # ç¡®ä¿èƒ½æ‰¾åˆ°modelæ¨¡å—
            model_path = os.path.join(self.project_root, 'model')
            if model_path not in sys.path:
                sys.path.append(model_path)
            from sac2 import EnhancedSAC, Actor, Critic, ActionConverter
            
            # ä»checkpointè·å–é…ç½®
            if isinstance(checkpoint, dict) and 'training_config' in checkpoint:
                config = checkpoint['training_config']
                
                # é‡æ–°æ„å»ºæ™ºèƒ½ä½“
                agent = EnhancedSAC(config['state_dim'], config['action_dim'], device='cpu')
                
                # åŠ è½½æ¨¡å‹æƒé‡
                agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                agent.critic.load_state_dict(checkpoint['critic_state_dict'])
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                agent.actor.eval()
                agent.critic.eval()
                
                return {
                    'agent': agent,
                    'running_stats': None,  # SACé€šå¸¸ä¸ä½¿ç”¨è¿è¡Œç»Ÿè®¡
                    'state_keys': checkpoint.get('state_keys', None)
                }
            else:
                print("âŒ SACæ¨¡å‹æ ¼å¼ä¸æ”¯æŒ")
                return None
                
        except Exception as e:
            print(f"âŒ SACæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def get_carbon_intensity(self, electricity_price):
        """æ ¹æ®ç”µä»·è·å–å¯¹åº”çš„ç¢³å¼ºåº¦"""
        if electricity_price <= 0.2:  # ä½è°·æœŸ
            return self.carbon_intensity_mapping['low_valley']
        elif electricity_price >= 0.8:  # é«˜å³°æœŸ
            return self.carbon_intensity_mapping['peak']
        else:  # å¹³æ®µæœŸ
            return self.carbon_intensity_mapping['flat']
    
    def get_random_action(self, state, env):
        """ç”ŸæˆéšæœºåŠ¨ä½œï¼ˆä½¿ç”¨ç¯å¢ƒçš„åŠ¨ä½œæ©ç ï¼‰"""
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # æ ¹æ®æ©ç éšæœºé€‰æ‹©æœ‰æ•ˆåŠ¨ä½œ
        action = {}
        
        # EVåŠŸç‡é€‰æ‹©
        ev_valid_indices = [i for i, valid in enumerate(action_mask['ev_power']) if valid]
        if ev_valid_indices:
            ev_idx = random.choice(ev_valid_indices)
            action['ev_power'] = env.action_space['ev_power'][ev_idx]
        else:
            action['ev_power'] = 0
        
        # ESSåŠŸç‡é€‰æ‹©
        ess_valid_indices = [i for i, valid in enumerate(action_mask['battery_power']) if valid]
        if ess_valid_indices:
            ess_idx = random.choice(ess_valid_indices)
            action['battery_power'] = env.action_space['battery_power'][ess_idx]
        else:
            action['battery_power'] = 0
        
        # å…¶ä»–è®¾å¤‡éšæœºé€‰æ‹©
        action['wash_machine_schedule'] = random.choice(env.action_space['wash_machine_schedule'])
        action['Air_conditioner_set_temp'] = random.choice(env.action_space['Air_conditioner_set_temp'])
        action['Air_conditioner_set_temp2'] = random.choice(env.action_space['Air_conditioner_set_temp2'])
        action['ewh_set_temp'] = random.choice(env.action_space['ewh_set_temp'])
        
        return action
    
    def get_model_action(self, state, env, strategy_key='proposed_rl'):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è·å–åŠ¨ä½œï¼ˆä½¿ç”¨ç¯å¢ƒçš„åŠ¨ä½œæ©ç ï¼‰"""
        model = self.loaded_models.get(strategy_key)
        if model is None:
            raise ValueError(f"âŒ {strategy_key} æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•æ‰§è¡Œæ¨¡å‹åŠ¨ä½œ")
        
        try:
            if strategy_key == 'proposed_rl':
                action = self.get_ppo_action(state, env, model)
            elif strategy_key == 'rainbow_dqn':
                action = self.get_rainbow_dqn_action(state, env, model)
            elif strategy_key == 'ddpg':
                action = self.get_ddpg_action(state, env, model)
            elif strategy_key == 'td3':
                action = self.get_td3_action(state, env, model)
            elif strategy_key == 'sac':
                action = self.get_sac_action(state, env, model)
            else:
                raise ValueError(f"âŒ æœªçŸ¥çš„ç­–ç•¥ç±»å‹: {strategy_key}")
            
            # æ£€æŸ¥åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            if action is None:
                raise ValueError(f"âŒ {strategy_key} æ¨¡å‹è¿”å›NoneåŠ¨ä½œï¼Œæ¨¡å‹æ¨ç†å¤±è´¥")
            
            return action
                
        except Exception as e:
            print(f"âŒ {strategy_key} æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…çŸ¥é“çœŸæ­£çš„é—®é¢˜
    
    def get_ppo_action(self, state, env, model):
        """è·å–PPOæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.shared_backbone.to('cpu').float()
        for branch in agent.actor_branches.values():
            branch.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨æ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¼ å…¥åŠ¨ä½œæ©ç ï¼‰
        with torch.no_grad():
            action_result = agent.take_action(normalized_state, action_mask)
            action_dict = action_result[0]  # å–actionså­—å…¸
            
            # éªŒè¯åŠ¨ä½œå­—å…¸çš„æœ‰æ•ˆæ€§
            if not isinstance(action_dict, dict):
                raise ValueError(f"âŒ PPOæ¨¡å‹è¿”å›äº†æ— æ•ˆçš„åŠ¨ä½œæ ¼å¼: {type(action_dict)}")
            
            # æ£€æŸ¥å¿…è¦çš„åŠ¨ä½œé”®æ˜¯å¦å­˜åœ¨
            required_keys = ['ev_power', 'battery_power', 'wash_machine_schedule', 
                           'Air_conditioner_set_temp', 'Air_conditioner_set_temp2', 'ewh_set_temp']
            for key in required_keys:
                if key not in action_dict:
                    raise ValueError(f"âŒ PPOåŠ¨ä½œå­—å…¸ç¼ºå°‘å¿…è¦çš„é”®: {key}")
        
        return action_dict
    
    def get_rainbow_dqn_action(self, state, env, model):
        """è·å–Rainbow DQNæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # è·å–ç¯å¢ƒçš„åŠ¨ä½œæ©ç 
        action_mask = env.get_action_mask(state)
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.shared_backbone.to('cpu').float()
        for branch in agent.q_branches.values():
            branch.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨DQNæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¼ å…¥åŠ¨ä½œæ©ç ï¼Œä¸æ¢ç´¢ï¼‰
        with torch.no_grad():
            action_dict = agent.select_action(normalized_state.cpu(), action_mask, explore=False)
        
        return action_dict
    
    def get_ddpg_action(self, state, env, model):
        """è·å–DDPGæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        agent.critic.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨DDPGæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            continuous_action = agent.actor(normalized_state).cpu().numpy().flatten()
            # ä½¿ç”¨åŠ¨ä½œè½¬æ¢å™¨å°†è¿ç»­åŠ¨ä½œè½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œ
            action_dict = agent.converter.continuous_to_discrete(continuous_action)
            
            # éªŒè¯åŠ¨ä½œå­—å…¸çš„æœ‰æ•ˆæ€§
            if not isinstance(action_dict, dict):
                raise ValueError(f"âŒ DDPGåŠ¨ä½œè½¬æ¢å™¨è¿”å›äº†æ— æ•ˆçš„åŠ¨ä½œæ ¼å¼: {type(action_dict)}")
            
            # æ£€æŸ¥å¿…è¦çš„åŠ¨ä½œé”®æ˜¯å¦å­˜åœ¨
            required_keys = ['ev_power', 'battery_power', 'wash_machine_schedule', 
                           'Air_conditioner_set_temp', 'Air_conditioner_set_temp2', 'ewh_set_temp']
            for key in required_keys:
                if key not in action_dict:
                    raise ValueError(f"âŒ DDPGåŠ¨ä½œå­—å…¸ç¼ºå°‘å¿…è¦çš„é”®: {key}")
        
        return action_dict
    
    def get_td3_action(self, state, env, model):
        """è·å–TD3æ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # çŠ¶æ€æ ‡å‡†åŒ–
        if model['running_stats'] is not None:
            normalized_state = model['running_stats'].normalize(state_tensor).clamp(-5, 5)
        else:
            normalized_state = state_tensor
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        agent.critic1.to('cpu').float()
        agent.critic2.to('cpu').float()
        normalized_state = normalized_state.float()
        
        # ä½¿ç”¨TD3æ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            continuous_action = agent.actor(normalized_state).cpu().numpy().flatten()
            # ä½¿ç”¨åŠ¨ä½œè½¬æ¢å™¨å°†è¿ç»­åŠ¨ä½œè½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œ
            action_dict = agent.converter.continuous_to_discrete(continuous_action)
        
        return action_dict
    
    def get_sac_action(self, state, env, model):
        """è·å–SACæ¨¡å‹åŠ¨ä½œ"""
        agent = model['agent']
        
        # å°†çŠ¶æ€è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
        state_vector = self.state_to_vector(state, model['state_keys'])
        state_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to('cpu')
        
        # ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶åœ¨CPUä¸Šå¹¶è®¾ç½®ä¸ºfloat32
        agent.actor.to('cpu').float()
        agent.critic.to('cpu').float()
        state_tensor = state_tensor.float()
        
        # ä½¿ç”¨SACæ™ºèƒ½ä½“é¢„æµ‹åŠ¨ä½œï¼ˆä¸æ·»åŠ å™ªå£°ï¼Œç”¨äºè¯„ä¼°ï¼‰
        with torch.no_grad():
            action_dict = agent.select_action(state_tensor)
        
        return action_dict
    
    def state_to_vector(self, state, state_keys):
        """å°†çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºå‘é‡"""
        if state_keys:
            state_vector = [state[k] for k in state_keys]
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæŒ‰å­—æ¯é¡ºåºæ’åº
            ordered_keys = sorted(state.keys())
            state_vector = [state[k] for k in ordered_keys]
        return state_vector
    
    def apply_device_mask(self, action, mask_type):
        """åº”ç”¨è®¾å¤‡æ©ç ï¼ˆå‚¨èƒ½è®¾å¤‡çš„å¯ç”¨/ç¦ç”¨ï¼‰"""
        masked_action = action.copy()
        
        # ä¸ºç¡®ä¿æ§åˆ¶å˜é‡ä¸¥æ ¼æ€§ï¼ŒåŸºç¡€ç”¨ç”µè®¾å¤‡ä½¿ç”¨å›ºå®šç­–ç•¥
        masked_action['Air_conditioner_set_temp'] = 24     # å›ºå®šæ¸©åº¦
        masked_action['Air_conditioner_set_temp2'] = 24    # å›ºå®šæ¸©åº¦
        masked_action['ewh_set_temp'] = 55                 # å›ºå®šæ¸©åº¦
        
        if mask_type == 'baseline':
            # å¯¹ç…§ç»„ï¼šç¦ç”¨å‚¨èƒ½åŠŸèƒ½
            masked_action['battery_power'] = 0
            if masked_action['ev_power'] < 0:
                masked_action['ev_power'] = 0
                
        elif mask_type == 'v2g_only':
            # V2Gç»„ï¼šéƒ¨åˆ†å‚¨èƒ½åŠŸèƒ½
            masked_action['battery_power'] = 0
            
        elif mask_type == 'full':
            # å®Œæ•´ä¼˜åŒ–ç»„ï¼šå…è®¸æ‰€æœ‰åŠŸèƒ½
            pass
        
        return masked_action
    
    def calculate_home_total_carbon(self, env, electricity_price):
        """è®¡ç®—å®¶åº­æ€»è´Ÿè·çš„ç¢³æ’æ”¾"""
        carbon_intensity = self.get_carbon_intensity(electricity_price)
        
        # è·å–å®¶åº­æ€»è´Ÿè·
        total_home_load = env.total_load_compute()
        
        # åªæœ‰å‡€è´­ç”µæ‰äº§ç”Ÿç¢³æ’æ”¾
        if total_home_load > 0:  # å®¶åº­éœ€è¦ä»ç”µç½‘è´­ç”µ
            step_carbon = total_home_load * 0.5 * carbon_intensity
            grid_purchase = total_home_load * 0.5
            grid_sale = 0
        else:  # å®¶åº­å‘ç”µç½‘å”®ç”µæˆ–å¹³è¡¡
            step_carbon = 0
            grid_purchase = 0
            grid_sale = abs(total_home_load) * 0.5
        
        return step_carbon, grid_purchase, grid_sale, carbon_intensity, total_home_load
    
    def run_single_episode(self, strategy_key, config_key, episode_num):
        """è¿è¡Œå•ä¸ªepisode"""
        env = HomeEnergyManagementEnv()
        state = env.reset()
        
        strategy_config = self.strategies[strategy_key]
        config = self.configurations[config_key]
        
        # åˆå§‹åŒ–episodeæ•°æ®è®°å½•
        episode_data = {
            'episode': episode_num,
            'strategy': strategy_config['name'],
            'configuration': config['name'],
            'total_carbon': 0,
            'total_grid_purchase': 0,
            'total_grid_sale': 0,
            'ev_charge_energy': 0,
            'ev_discharge_energy': 0,
            'ess_charge_energy': 0,
            'ess_discharge_energy': 0,
            'vehicle_storage_actions': 0,
            'battery_storage_actions': 0,
            'carbon_intensity_avg': 0,
            'home_load_avg': 0,
            'high_carbon_purchase': 0,  # é«˜ç¢³æ—¶æ®µè´­ç”µé‡
            'low_carbon_purchase': 0,   # ä½ç¢³æ—¶æ®µè´­ç”µé‡
            'ev_initial_soc': state['ev_battery_state'] / 24,
            'ess_initial_soc': state['ess_state'] / 24,
            'ev_final_soc': 0,
            'ess_final_soc': 0
        }
        
        for step in range(self.episode_length):
            # è·å–ç­–ç•¥åŠ¨ä½œ
            if strategy_key == 'random':
                raw_action = self.get_random_action(state, env)
            else:
                try:
                    raw_action = self.get_model_action(state, env, strategy_key)
                except Exception as e:
                    print(f"âŒ Episode {episode_num}, Step {step}: {strategy_key} æ¨¡å‹å¤±è´¥: {e}")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œåœæ­¢å®éªŒ
            
            # åº”ç”¨è®¾å¤‡æ©ç 
            action = self.apply_device_mask(raw_action, config['mask_type'])
            
            # æ‰§è¡ŒåŠ¨ä½œï¼Œæ›´æ–°ç¯å¢ƒçŠ¶æ€
            next_state, reward, done = env.step(state, action)
            
            # è®¡ç®—å½“å‰æ­¥éª¤çš„å®¶åº­æ€»ç¢³æ’æ”¾
            step_carbon, grid_purchase, grid_sale, carbon_intensity, total_home_load = self.calculate_home_total_carbon(
                env, state['electricity_price']
            )
            
            # è®°å½•ç¢³æ’æ”¾å’Œç”µç½‘äº¤äº’æ•°æ®
            episode_data['total_carbon'] += step_carbon
            episode_data['total_grid_purchase'] += grid_purchase
            episode_data['total_grid_sale'] += grid_sale
            episode_data['carbon_intensity_avg'] += carbon_intensity
            episode_data['home_load_avg'] += abs(total_home_load)
            
            # è®°å½•é«˜ç¢³/ä½ç¢³æ—¶æ®µçš„è´­ç”µé‡
            if carbon_intensity >= 0.9:  # é«˜ç¢³æ—¶æ®µ
                episode_data['high_carbon_purchase'] += grid_purchase
            elif carbon_intensity <= 0.3:  # ä½ç¢³æ—¶æ®µ
                episode_data['low_carbon_purchase'] += grid_purchase
            
            # è®°å½•èƒ½é‡æ•°æ®
            if action['ev_power'] > 0:
                episode_data['ev_charge_energy'] += action['ev_power'] * 0.5
            elif action['ev_power'] < 0:
                episode_data['ev_discharge_energy'] += abs(action['ev_power']) * 0.5
                episode_data['vehicle_storage_actions'] += 1
            
            if action['battery_power'] > 0:
                episode_data['ess_charge_energy'] += action['battery_power'] * 0.5
            elif action['battery_power'] < 0:
                episode_data['ess_discharge_energy'] += abs(action['battery_power']) * 0.5
                episode_data['battery_storage_actions'] += 1
            
            # æ›´æ–°çŠ¶æ€
            state = next_state
        
        # è®°å½•æœ€ç»ˆSOC
        episode_data['ev_final_soc'] = state['ev_battery_state'] / 24
        episode_data['ess_final_soc'] = state['ess_state'] / 24
        
        # è®¡ç®—å¹³å‡å€¼
        episode_data['carbon_intensity_avg'] /= self.episode_length
        episode_data['home_load_avg'] /= self.episode_length
        
        return episode_data
    
    def run_experiment_group(self, strategy_key, config_key):
        """è¿è¡Œä¸€ç»„å®éªŒ"""
        strategy_name = self.strategies[strategy_key]['name']
        config_name = self.configurations[config_key]['name']
        group_key = f"{strategy_key}_{config_key}"
        
        print(f"ğŸ”„ æ­£åœ¨è¿è¡Œ {strategy_name} - {config_name}...")
        
        results = []
        for episode in range(self.num_episodes):
            episode_data = self.run_single_episode(strategy_key, config_key, episode)
            results.append(episode_data)
        
        self.results[group_key] = results
        print(f"âœ… {strategy_name} - {config_name} å®Œæˆ")
        
        return results
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒ...")
        
        # è¿è¡Œæ‰€æœ‰ç­–ç•¥å’Œé…ç½®çš„ç»„åˆ
        for strategy_key in self.strategies.keys():
            for config_key in self.configurations.keys():
                self.run_experiment_group(strategy_key, config_key)
        
        print("\nğŸ‰ æ‰€æœ‰å®éªŒç»„å®Œæˆï¼")
    
    def analyze_results(self):
        """åˆ†æå®éªŒç»“æœ"""
        # è½¬æ¢ä¸ºDataFrame
        all_results = []
        for group_key, results in self.results.items():
            for result in results:
                result['group_key'] = group_key
                all_results.append(result)
        
        df_all = pd.DataFrame(all_results)
        
        # è®¡ç®—å„ç»„å¹³å‡å€¼
        results_summary = {}
        for group_key, results in self.results.items():
            df = pd.DataFrame(results)
            results_summary[group_key] = {
                'avg_carbon': df['total_carbon'].mean(),
                'avg_grid_purchase': df['total_grid_purchase'].mean(),
                'avg_grid_sale': df['total_grid_sale'].mean(),
                'avg_ev_charge': df['ev_charge_energy'].mean(),
                'avg_ev_discharge': df['ev_discharge_energy'].mean(),
                'avg_ess_charge': df['ess_charge_energy'].mean(),
                'avg_ess_discharge': df['ess_discharge_energy'].mean(),
                'avg_high_carbon_purchase': df['high_carbon_purchase'].mean(),
                'avg_low_carbon_purchase': df['low_carbon_purchase'].mean(),
                'avg_vehicle_storage_actions': df['vehicle_storage_actions'].mean(),
                'avg_battery_storage_actions': df['battery_storage_actions'].mean(),
                'strategy': df['strategy'].iloc[0],
                'configuration': df['configuration'].iloc[0]
            }
        
        # æ‰“å°ç»“æœåˆ†æ
        print(f"\n{'='*70}")
        print(f"ğŸ“Š ç®—æ³•ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”å®éªŒç»“æœåˆ†æ")
        print(f"{'='*70}")
        
        # å„ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”
        print(f"\nğŸ” å®Œæ•´é…ç½®ä¸‹å„ç®—æ³•ç­–ç•¥ç¢³æ’æ”¾å¯¹æ¯”ï¼š")
        print(f"{'ç®—æ³•ç­–ç•¥':<20} {'å¹³å‡ç¢³æ’æ”¾(kg CO2)':<20}")
        print(f"{'-'*45}")
        
        carbon_data = {}
        for strategy_key, strategy in self.strategies.items():
            group_key = f"{strategy_key}_full_optimization"
            if group_key in results_summary:
                summary = results_summary[group_key]
                carbon_data[strategy['name']] = summary['avg_carbon']
                print(f"{strategy['name']:<20} {summary['avg_carbon']:<20.2f}")
        
        # è¯¦ç»†çš„ç¢³æ’æ”¾å¯¹æ¯”æ•°æ®æ‰“å°
        print(f"\nğŸ“Š è¯¦ç»†ç¢³æ’æ”¾å¯¹æ¯”æ•°æ®:")
        for strategy_name, carbon_value in carbon_data.items():
            print(f"  {strategy_name}: {carbon_value:.4f} kg CO2")
        
        # å¦‚æœæœ‰éšæœºç­–ç•¥ï¼Œè®¡ç®—æ”¹è¿›å¹…åº¦
        if 'random' in [k for k in self.strategies.keys()]:
            random_key = "random_full_optimization"
            if random_key in results_summary:
                random_carbon = results_summary[random_key]['avg_carbon']
                print(f"\nğŸ“ˆ ç›¸å¯¹éšæœºç­–ç•¥çš„æ”¹è¿›:")
                print(f"  éšæœºç­–ç•¥åŸºå‡†: {random_carbon:.4f} kg CO2")
                
                for strategy_key, strategy in self.strategies.items():
                    if strategy_key != 'random':
                        model_key = f"{strategy_key}_full_optimization"
                        if model_key in results_summary:
                            model_carbon = results_summary[model_key]['avg_carbon']
                            improvement = random_carbon - model_carbon
                            improvement_pct = (improvement / random_carbon * 100) if random_carbon > 0 else 0
                            print(f"  {strategy['name']}: å‡å°‘ {improvement:.4f} kg CO2 ({improvement_pct:.2f}%)")

        
        return results_summary, df_all
    
    def create_visualization(self, results_summary):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        plt.style.use('default')
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        
        # ç®—æ³•ç­–ç•¥çš„ç¢³æ’æ”¾å¯¹æ¯”
        strategies = list(self.strategies.keys())
        strategy_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']
        
        carbons = []
        strategy_names = []
        colors = []
        
        for i, strategy_key in enumerate(strategies):
            group_key = f"{strategy_key}_full_optimization"
            if group_key in results_summary:
                carbons.append(results_summary[group_key]['avg_carbon'])
                # è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼šä½¿ç”¨ç®€æ´çš„è‹±æ–‡åç§°
                if strategy_key == 'random':
                    strategy_names.append('Random Strategy')
                elif strategy_key == 'proposed_rl':
                    strategy_names.append('PPO Algorithm')
                elif strategy_key == 'rainbow_dqn':
                    strategy_names.append('Rainbow DQN Algorithm')
                elif strategy_key == 'ddpg':
                    strategy_names.append('DDPG Algorithm')
                elif strategy_key == 'td3':
                    strategy_names.append('TD3 Algorithm')
                elif strategy_key == 'sac':
                    strategy_names.append('SAC Algorithm')
                else:
                    # é»˜è®¤ä½¿ç”¨ç­–ç•¥keyçš„è‹±æ–‡å½¢å¼
                    strategy_names.append(strategy_key.upper() + ' Algorithm')
                colors.append(strategy_colors[i % len(strategy_colors)])
        
        x = np.arange(len(strategy_names))
        bars = ax.bar(x, carbons, color=colors, alpha=0.8, edgecolor='black', width=0.6)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                        f'{height:.2f}', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        ax.set_ylabel('Carbon Emissions (kg CO2)', fontweight='bold', fontsize=12)
        ax.set_title('Carbon Emissions Comparison of Different Algorithms', fontweight='bold', fontsize=16)
        ax.set_xticks(x)
        ax.set_xticklabels(strategy_names, fontsize=12)
        ax.grid(True, alpha=0.3, axis='y')
        
        # è®¾ç½®yè½´èŒƒå›´ï¼Œç•™å‡ºç©ºé—´æ˜¾ç¤ºæ•°å€¼æ ‡ç­¾
        if carbons:
            max_carbon = max(carbons)
            ax.set_ylim(0, max_carbon * 1.1)
        
        plt.tight_layout()
        # ç¡®ä¿figuresç›®å½•å­˜åœ¨
        figures_dir = os.path.join(self.project_root, 'figures', 'experiment_results')
        os.makedirs(figures_dir, exist_ok=True)
        figures_path = os.path.join(figures_dir, 'strategy_carbon_comparison.png')
        plt.savefig(figures_path, dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜
        print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º: strategy_carbon_comparison.png")
    
    def save_results(self, results_summary):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç¡®ä¿resultsç›®å½•å­˜åœ¨
        results_dir = os.path.join(self.project_root, 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        for group_key, results in self.results.items():
            df = pd.DataFrame(results)
            df.to_csv(os.path.join(results_dir, f'{group_key}_strategy_comparison_{timestamp}.csv'), index=False)
        
        # ä¿å­˜å¯¹æ¯”åˆ†æç»“æœ
        summary_df = pd.DataFrame(results_summary).T
        summary_df.to_csv(os.path.join(results_dir, f'strategy_comparison_summary_{timestamp}.csv'))
        
        print(f"\nğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜åˆ° ../results/ ç›®å½•")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå®éªŒå¯¹è±¡
    experiment = StrategyCarbonComparison()
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    experiment.run_all_experiments()
    
    # åˆ†æç»“æœ
    results_summary, df_all = experiment.analyze_results()
    
    # åˆ›å»ºå¯è§†åŒ–
    experiment.create_visualization(results_summary)
    
    # ä¿å­˜ç»“æœ
    experiment.save_results(results_summary)

if __name__ == "__main__":
    main()
